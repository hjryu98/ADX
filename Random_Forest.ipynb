{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcoPXNFUgwIn"
      },
      "source": [
        "###$\\color{blue}{\\text{3.0. Environmental Set-up & Data Loading}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d77gYCjpgwIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55eb28a-17c6-4f80-f597-fca242a94e4f"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# enter the foldername in your Google Drive where you have saved the unzipped\n",
        "FOLDERNAME =  'ADX/'\n",
        "\n",
        "assert FOLDERNAME is not None, 'ERROR'\n",
        "\n",
        "%cd drive/My\\ Drive\n",
        "%cp -r $FOLDERNAME ../../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9q2ubx0gwIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6911df8a-f67a-4ca9-b4ee-9a734b32de08"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Part 1.1에서 전처리하여 저장한 데이터 Import\n",
        "df = pd.read_pickle('./ADX/Data_RealEstate/dataset_preprocessing_team1real_v2.pickle')\n",
        "y_price = df.loc[:, '거래금액(만원)_adj']\n",
        "df_ = df.drop('거래금액(만원)_adj', 1)\n",
        "\n",
        "# 추후에 Implementation for Real-World Practice에 사용할 Test Data\n",
        "\n",
        "#우리가 testset을 가지고 있기 않기 때문에 에러발생 -> 주석처리\n",
        "#df_test = pd.read_csv('./ADX/Data_RealEstate/testset.csv', encoding ='cp949')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-f1308930ba9d>:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  df_ = df.drop('거래금액(만원)_adj', 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIhcy46zDdlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442a6f80-838d-412f-8175-ee5e228920ca"
      },
      "source": [
        "# 한글 나눔포트 사용\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "from matplotlib import font_manager, rc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20180306-3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGmrPvr5gwIr"
      },
      "source": [
        "###$\\color{blue}{\\text{3.1. Data split & Normalization}}$\n",
        "\n",
        "모델을 튜닝하기 위한 validation set 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp646yASgwIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce1d9295-6f09-4d4b-bf1d-8e51c1a1849f"
      },
      "source": [
        "def splitData(df, ratio, y_column):\n",
        "    \n",
        "    columns_ = df.columns\n",
        "    # Subsample the data\n",
        "    mask = list(range(0,df.shape[0], ratio))\n",
        "    X_val = df.iloc[mask, :].drop(y_column, 1)\n",
        "    y_val = df.iloc[mask][y_column]\n",
        "    \n",
        "    mask = ~df.index.isin(mask)\n",
        "    X_train = df.loc[mask, :].drop(y_column, 1)\n",
        "    y_train = df.loc[mask, y_column]\n",
        "    \n",
        "    return X_train, y_train, X_val, y_val\n",
        "\n",
        "# train set, validation set split \n",
        "# train set, validation set = 4 : 1\n",
        "\n",
        "X_train, y_train, X_val, y_val = splitData(df_, 5, y_column = '평당가격') \n",
        "\n",
        "\n",
        "#################################################################################\n",
        "# TODO: 연속형 변수에 대해서 Z normalize를 설계 및 적용                         #\n",
        "# 대표적으로 Z normalize와 min max normalize가 존재 \n",
        "# 이번에는 Z-normalize를 사용!!\n",
        "#\n",
        "# 1. training dataset에 normalize하는 함수 생성(validation/ test에 사용할 cache \n",
        "# 저장)\n",
        "# 2. validation set과 test set을 normalize하는 함수 생성 및 적용\n",
        "#################################################################################\n",
        "\n",
        "##1. \n",
        "def z_normalize(data, column):\n",
        "    temp_df = data[column]\n",
        "    normalized_df = (temp_df - temp_df.mean()) / temp_df.std()\n",
        "    cache = {}\n",
        "    cache['mean'] = temp_df.mean()\n",
        "    cache['std'] = temp_df.std()\n",
        "    return normalized_df, cache\n",
        "\n",
        "    \n",
        "##2. \n",
        "def z_normalize_val(data, column, cache):\n",
        "    temp_df = data[column]\n",
        "    normalized_df = (temp_df - cache['mean']) / cache['std']\n",
        "    return normalized_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-9c5607a99a78>:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  X_val = df.iloc[mask, :].drop(y_column, 1)\n",
            "<ipython-input-4-9c5607a99a78>:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  X_train = df.loc[mask, :].drop(y_column, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZdqDa00alAm"
      },
      "source": [
        "# 위 block에서 만들어진 z_normalize와 z_normalize_val 적용 (Error 날 경우 다시 고민할 것)\n",
        "X_train_norm = X_train.copy()\n",
        "X_train_norm.loc[:, ['전용/연면적(㎡)','층','건물년식']], cache = z_normalize(X_train, ['전용/연면적(㎡)','층','건물년식'])\n",
        "X_val_norm = X_val.copy()\n",
        "X_val_norm.loc[:, ['전용/연면적(㎡)','층','건물년식']] = z_normalize_val(X_val, ['전용/연면적(㎡)','층','건물년식'], cache)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TcNs7nRgwIu"
      },
      "source": [
        "###$\\color{blue}{\\text{3.2. Random Forest}}$\n",
        "\n",
        "랜덤포레스트 (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
        "\n",
        "**Hyperparameter Optimization (Tuning)**. 랜덤포레스트에서 hyperparameter들은 n_estimators, criterion, max_depth, min_samples_split, min_samples_leaf 등등이 존재한다. 이러한 하이퍼파라미터는 모델 성능에 큰 영향을 미치므로 training data와 validation data를 활용하여서 좋은 성능의 모델을 출력\n",
        "\n",
        "**Approximate results**. ㎡당 가격의 MAE와 ㎡당 가격을 추정 상가 가격으로 변환하여 MAE를 계산 (MAE의 minimum을 찾는 행위가 Hyperparameter optimization을 의미하며 최대로 개선된 모형을 사용하는 것이 바람직함)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBKBtxzFgwIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8432dcf9-103e-4df2-c70f-1527cd542a4e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "best_rf = None # store the best model into this \n",
        "best_mse = 1e10\n",
        "best_hyperparameter = None\n",
        "results = {}\n",
        "n_estimators = [50, 100, 150]\n",
        "max_depths = [100, 200, 300]\n",
        "ects = None\n",
        "\n",
        "\n",
        "#################################################################################\n",
        "# TODO: validation dataset을 활용하여 하이퍼 파라미터를 조정하고 가장 좋은 모델 # \n",
        "# 을 저장하여 test dataset에 사용                                               #\n",
        "#                                                                               \n",
        "# 1. n_estimators, max_depth을 조절하여 가장 좋은 모델을 'best_rf'에 저장, 가장 \n",
        "# 좋은 모델의 하이퍼 파라미터를 'best_hyperparamter'에 저장. 모델의 성능 비교는\n",
        "# validation set의 MSE를 참조하고 가장 좋은 모델의 MSE를 'best_MSE'에 저장.\n",
        "#\n",
        "# 2. 현재 가장 좋은 모델의 하이퍼파라미터를 고정하고 Random Forest 모델의 다른 \n",
        "# hyperparameter를 조절하여 성능 차이 비교 (위의 scikit-learn 문서 참조)\n",
        "#################################################################################\n",
        "\n",
        "#1\n",
        "#n_estimator, max_depth를 바꿔가면서 하이퍼파라미터 튜닝\n",
        "for est_num in n_estimators:\n",
        "    for depth in max_depths:\n",
        "        cur_RF = RandomForestRegressor(n_estimators=est_num, max_depth=depth, oob_score=True)\n",
        "        cur_RF.fit(X_train_norm, y_train)\n",
        "        cur_pred = cur_RF.predict(X_val_norm)\n",
        "        cur_mse = mean_squared_error(y_val, cur_pred)\n",
        "        \n",
        "        #MSE값이 이전 모델보다 작아질 경우에만 모델 갱신\n",
        "        if cur_mse <= best_mse:\n",
        "            best_rf = cur_RF\n",
        "            best_mse = cur_mse\n",
        "            best_hyperparameter = {'n_estimators':est_num, 'max_depths':depth}\n",
        "            print(\"Updated!  current model: \", best_rf,\"\\ncurrent MSE: \", cur_mse)\n",
        "\n",
        "#최종 하이퍼파라미터 출력       \n",
        "print(\"Best n_estimator :\", best_hyperparameter['n_estimators'], \"best max_depth :\", best_hyperparameter['max_depths'])\n",
        "\n",
        "best_n_estimator = best_hyperparameter['n_estimators']\n",
        "best_max_depth = best_hyperparameter['max_depths']\n",
        "\n",
        "#2\n",
        "############################################################\n",
        "#1에서 구한 최종 n_estimator, max_depth를 고정 후\n",
        "#max_features와 min_samples_leaf수를 바꿔가면서 모델 다시 최적화\n",
        "#max_features : node 분할 시 무작위로 선택되는 변수의 수\n",
        "#min_samples_leaf : 루트 노드에 남길 수 있는 최종 샘플의 개수\n",
        "############################################################\n",
        "\n",
        "import math\n",
        "mid = round(math.sqrt(X_train_norm.shape[1])/3)\n",
        "#강의자료를 기준으로 sqrt(변수의 개수)/3 으로 기준치 설정\n",
        "\n",
        "max_features = [mid, mid+1, mid+2, mid+3, mid+4]\n",
        "min_samples = [1,3,5,7]\n",
        "\n",
        "#max_features와 min_samples 를 바꿔가면서 하이퍼파라미터 튜닝\n",
        "for feat_num in max_features:\n",
        "    for min_num in min_samples:\n",
        "        cur_RF = RandomForestRegressor(n_estimators=best_n_estimator, max_depth=best_max_depth,\n",
        "                                       min_samples_leaf=min_num, max_features=feat_num, oob_score=True)\n",
        "        cur_RF.fit(X_train_norm, y_train)\n",
        "        cur_pred = cur_RF.predict(X_val_norm)\n",
        "        cur_mse = mean_squared_error(y_val, cur_pred)\n",
        "\n",
        "        #기존의 MSE보다 더 좋은 값이 나왔을 때 모델 갱신\n",
        "        if cur_mse <= best_mse:\n",
        "            best_rf = cur_RF\n",
        "            best_mse = cur_mse\n",
        "            best_hyperparameter['max_features'] = feat_num\n",
        "            best_hyperparameter['min_sample_leaf'] = min_num\n",
        "\n",
        "            print(\"Updated!  current model is \", best_rf, \"with MSE: \", cur_mse)\n",
        "        \n",
        "print(\"Finished! Best model is \", best_rf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated!  current model:  RandomForestRegressor(max_depth=100, n_estimators=50, oob_score=True) \n",
            "current MSE:  119453.40802746257\n",
            "Updated!  current model:  RandomForestRegressor(max_depth=100, oob_score=True) \n",
            "current MSE:  117120.9781278456\n",
            "Updated!  current model:  RandomForestRegressor(max_depth=200, oob_score=True) \n",
            "current MSE:  116838.33370268028\n",
            "Updated!  current model:  RandomForestRegressor(max_depth=100, n_estimators=150, oob_score=True) \n",
            "current MSE:  116197.80034667903\n",
            "Updated!  current model:  RandomForestRegressor(max_depth=200, n_estimators=150, oob_score=True) \n",
            "current MSE:  116177.35549428589\n",
            "Updated!  current model:  RandomForestRegressor(max_depth=300, n_estimators=150, oob_score=True) \n",
            "current MSE:  115944.50639109006\n",
            "Best n_estimator : 150 best max_depth : 300\n",
            "Updated!  current model is  RandomForestRegressor(max_depth=300, max_features=3, n_estimators=150,\n",
            "                      oob_score=True) with MSE:  114999.46349000276\n",
            "Updated!  current model is  RandomForestRegressor(max_depth=300, max_features=4, n_estimators=150,\n",
            "                      oob_score=True) with MSE:  114415.7724569384\n",
            "Updated!  current model is  RandomForestRegressor(max_depth=300, max_features=5, n_estimators=150,\n",
            "                      oob_score=True) with MSE:  114051.1821928433\n",
            "Finished! Best model is  RandomForestRegressor(max_depth=300, max_features=5, n_estimators=150,\n",
            "                      oob_score=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8efYET5EgwIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6481842-cc7b-4ec9-a2d2-50c182535fae"
      },
      "source": [
        "# Print your validation 거래금액 mae: this should be below 400,000\n",
        "# 위 코드 결과물을 기반으로 계산 (에러가 난다면 본 코드를 수정하거나 위 코드를 수정하여야 함)\n",
        "\n",
        "print('Validation MSE(㎡당 가격): ', np.mean(np.square(best_rf.predict(X_val_norm) - y_val)))\n",
        "print('Validation MAE(㎡당 가격):', np.mean(np.abs(best_rf.predict(X_val_norm) - y_val)))\n",
        "\n",
        "_price = X_val.loc[:, '전용/연면적(㎡)'] * best_rf.predict(X_val_norm)\n",
        "\n",
        "print('Validation MSE(거래 금액): ', np.mean(np.square(_price - y_val)))\n",
        "print('Validation MAE(거래 금액): ', np.mean(np.abs(_price - y_val)))\n",
        "print('Best parameters : ', best_hyperparameter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MSE(㎡당 가격):  114051.1821928433\n",
            "Validation MAE(㎡당 가격): 157.6685822213536\n",
            "Validation MSE(거래 금액):  1459575460544.5322\n",
            "Validation MAE(거래 금액):  175938.0975730838\n",
            "Best parameters :  {'n_estimators': 150, 'max_depths': 300, 'max_features': 5, 'min_sample_leaf': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnAg2uSHD02_"
      },
      "source": [
        "하기의 function을 사용하여 최적 모형의 Feature를 분석한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g97yVRk1D0gO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "outputId": "fe153a95-bb9b-4b61-80c8-3b2497a32d5e"
      },
      "source": [
        "def plot_feature_importance(importance_, features_,model_type):\n",
        "      dict_ = {'feature importance' : importance_, 'features' : features_}\n",
        "      df = pd.DataFrame(dict_)\n",
        "      df.sort_values(by=['feature importance'], ascending=False,inplace=True)\n",
        "      plt.figure(figsize=(10,10))\n",
        "      sns.barplot(x=df['feature importance'], y=df['features'])\n",
        "      plt.title(model_type + 'FEATURE IMPORTANCE')\n",
        "      plt.xlabel('FEATURE IMPORTANCE')\n",
        "      plt.ylabel('FEATURE NAMES')\n",
        "\n",
        "      \n",
        "plot_feature_importance(best_rf.feature_importances_, X_val.columns, 'RANDOM FOREST ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw7uZ4GsD7xj"
      },
      "source": [
        "$\\color{lightgreen}{\\text{Question}}$ : 랜덤 포레스트의 Feature importance에 대해서 설명하고 위의 결과에 대해서 분석하여 Markdown에 기술하세요.\n",
        " \n",
        "$\\color{lightgreen}{\\text{Answer}}$ : Feature importance는 불순도를 낮추는 정도를 나타내는 지표이다. scikit learn에서의 feature importance는 Gini 중요도를 기반으로 중요도를 측정한다. 하지만, high-cardinality 변수에 대해 overestimate하는 경향이 있다. 그래서 연속형 변수인 '전용/연면적'과 '건물년식'의 경우 importance가 높게 측정된 것으로 보인다. 나머지 변수는 feature engineering 과정에서 낮은 차원으로 변환하였기에 비교적 imporatance가 낮게 측정된 것으로 보인다.\n",
        "이런 경우에는 permutation feature importance와 같은 방법을 혼합하여 사용하면 개선된다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKykWnVjvQsO"
      },
      "source": [
        "###$\\color{blue}{\\text{3.3. AdaBoost}}$\n",
        "\n",
        "팀원 간 토론 및 서치를 통해 sklearn 내 AdaBoost 모형을 이해하고 구현. \n",
        "Hyperparameter optimization은 반드시 필요하며 각 코드 별로 주석을 달아 구현 사유를 함께 서술!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxcIoBbnvPiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51bff0a-af50-4a5b-b71a-5d572a848f22"
      },
      "source": [
        "#################################################################################\n",
        "# TODO: Random Forest와 동일한 데이터에 대해 AdaBoost 구현!\n",
        "#################################################################################\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from itertools import product\n",
        "\n",
        "best_ab = None # store the best model into this \n",
        "best_mse_ab = 1e10\n",
        "best_mae_ab = 1e10\n",
        "best_hyperparameter_ab = None\n",
        "results_ab = {}\n",
        "\n",
        "#max_depth, n_estimator, learning_rate 3가지 하이퍼파라미터 튜닝\n",
        "#learning_rate : boosting과정에서 부여되는 가중치\n",
        "max_deps = [10, 13, 16, 19, 22, 25] \n",
        "n_estimators_ab = [50, 100, 150]\n",
        "learning_rate = [1, 1.25, 1.5]\n",
        "\n",
        "#하이퍼파라미터 셋을 카테시안 곱으로 리스트화 하여 저장 후 iteration\n",
        "params = list(product(max_deps, n_estimators_ab, learning_rate))\n",
        "\n",
        "for par in params:\n",
        "  cur_ab = AdaBoostRegressor( DecisionTreeRegressor(max_depth = par[0]), n_estimators = par[1], learning_rate = par[2], loss = 'linear')\n",
        "  cur_ab.fit(X_train_norm, y_train)\n",
        "  cur_predicted = cur_ab.predict(X_val_norm)\n",
        "  cur_mse = mean_squared_error(y_val, cur_predicted)\n",
        "  cur_mae = mean_absolute_error(y_val, cur_predicted)\n",
        "\n",
        "  #이전과 동일한 방식으로 MSE기준으로 모델 갱신\n",
        "  if cur_mse <= best_mse_ab:\n",
        "    best_ab = cur_ab\n",
        "    best_mse_ab = cur_mse\n",
        "    best_mae_ab = cur_mae\n",
        "    best_hyperparameter_ab = {'max_depth': par[0], 'n_estimators': par[1], 'learning_rate': par[2]}\n",
        "    print(\"Updated! \\ncurrent model: \", best_ab,\n",
        "          \"\\ncurrent MSE: \", cur_mse,\n",
        "          \"\\ncurrent MAE: \", cur_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated! \n",
            "current model:  AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=10),\n",
            "                  learning_rate=1) \n",
            "current MSE:  666814.9220947715 \n",
            "current MAE:  602.6312389408494\n",
            "Updated! \n",
            "current model:  AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=13),\n",
            "                  learning_rate=1) \n",
            "current MSE:  255021.0838046785 \n",
            "current MAE:  336.0251705256989\n",
            "Updated! \n",
            "current model:  AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=13),\n",
            "                  learning_rate=1.25) \n",
            "current MSE:  247985.9018144872 \n",
            "current MAE:  334.12800339547573\n",
            "Updated! \n",
            "current model:  AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=16),\n",
            "                  learning_rate=1) \n",
            "current MSE:  162891.71165565305 \n",
            "current MAE:  232.2927459209894\n",
            "Updated! \n",
            "current model:  AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=19),\n",
            "                  learning_rate=1) \n",
            "current MSE:  117765.56827840696 \n",
            "current MAE:  156.9779756542545\n",
            "Updated! \n",
            "current model:  AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=22),\n",
            "                  learning_rate=1) \n",
            "current MSE:  98400.72494264091 \n",
            "current MAE:  122.04314352165099\n",
            "Updated! \n",
            "current model:  AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=25),\n",
            "                  learning_rate=1) \n",
            "current MSE:  84712.71119227193 \n",
            "current MAE:  101.57135056746948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Adaboost validation added for training set\n",
        "print('Validation MSE(㎡당 가격): ', np.mean(np.square(best_ab.predict(X_val_norm) - y_val)))\n",
        "print('Validation MAE(㎡당 가격):', np.mean(np.abs(best_ab.predict(X_val_norm) - y_val)))\n",
        "\n",
        "_price = X_val.loc[:, '전용/연면적(㎡)'] * best_ab.predict(X_val_norm)\n",
        "\n",
        "print('Validation MSE(거래 금액): ', np.mean(np.square(_price - y_val)))\n",
        "print('Validation MAE(거래 금액): ', np.mean(np.abs(_price - y_val)))\n",
        "print('Best parameters : ', best_hyperparameter_ab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42PN64-_z4kl",
        "outputId": "1a23b136-5018-495b-8eb0-67e045aa6833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MSE(㎡당 가격):  84712.71119227193\n",
            "Validation MAE(㎡당 가격): 101.57135056746948\n",
            "Validation MSE(거래 금액):  1478880670392.9236\n",
            "Validation MAE(거래 금액):  176776.93359691257\n",
            "Best parameters :  {'max_depth': 25, 'n_estimators': 50, 'learning_rate': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Nvcmw2SgwI0"
      },
      "source": [
        "###$\\color{blue}{\\text{3.4. Implementation for Real-World Practice}}$\n",
        "\n",
        "새로운 데이터가 들어왔을 때, 지금까지 구현 된 과정을 자동으로 거쳐 새로운 input으로서 모델에 입력하고 산출물을 받을 수 있도록 구현 (test-set 개념으로 진행) ** Random Forest와 AdaBoost 두 모형 모두 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s38WwgcgwI0"
      },
      "source": [
        "testy = df_test.loc[:, '거래금액(만원)']\n",
        "y_real = []\n",
        "for i in np.array(df_test.loc[:, '거래금액(만원)']) :\n",
        "    y_real.append(float(i.replace(',', '')))\n",
        "df_test = df_test.drop('거래금액(만원)', 1)\n",
        "y_price = y_real / df_test.loc[:, '전용/연면적(㎡)']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PIbm1j-gwI3"
      },
      "source": [
        "import datetime\n",
        "import math\n",
        "\n",
        "# 하기의 새로운 df를 Part 1.1 내 df로 간주하고 진행할 것.\n",
        "df = df_test.copy()\n",
        "\n",
        "#################################################################################\n",
        "# TODO: Test set 동일한 처리과정 만들기                                         #\n",
        "#                                                                               \n",
        "# Part 1.1에서 만든 방법론을 적용 (Null은 없다고 가정 - 이미 처리했음)\n",
        "# 1. 데이터 타입처리 (계약년월, 건축년도)\n",
        "# 2. 지역구 단위의 행정구역 새로운 변수 생성 (변수명 '지역구')\n",
        "# 3. 건물 년식 일 단위로 하여 새로운 변수 생성 (변수명 '건물년식') \n",
        "# 4. 평당가격 변수 추가 \n",
        "# 5. 과제 1에서 만든 새로운 파생 변수 생성  \n",
        "#################################################################################\n",
        "#1\n",
        "contract_date = []\n",
        "for i,j in np.array(df[['계약년월', '계약일']]):\n",
        "  contract_date.append(datetime.datetime(int(str(i)[:4]), int(str(i)[4:6]), int(j)))\n",
        "\n",
        "df.loc[:, '계약날짜'] = contract_date\n",
        "\n",
        "construct_yr = []\n",
        "\n",
        "for i in np.array(df['건축년도']):\n",
        "  construct_yr.append(datetime.datetime(int(i), 1, 1))\n",
        "\n",
        "df['건축년도'] = construct_yr\n",
        "\n",
        "#2\n",
        "address_type = []\n",
        "\n",
        "for i in np.array(df['시군구']):\n",
        "  idx1 = i.find('서울특별시')\n",
        "\n",
        "  if i.find('구로구') >= 0:\n",
        "    idx2 = i.find('구로구')\n",
        "    address_type.append(i[idx1 + 5 : idx2 + 3].strip())\n",
        "  else:\n",
        "    idx2 = i.find('구')\n",
        "    address_type.append(i[idx1 + 5 : idx2 + 1].strip())\n",
        "\n",
        "df.loc[:, '지역구'] = address_type\n",
        "\n",
        "\n",
        "#3\n",
        "df.loc[:, '건물년식'] = df.apply(lambda x : (x['계약날짜'] - x['건축년도']).days, axis=1)\n",
        "\n",
        "\n",
        "#4\n",
        "df.loc[:, '평당가격'] = 0.0\n",
        "\n",
        "\n",
        "#5\n",
        "##ex.\n",
        "##지역구 열을 통해 종합주택가격지수라는 새로운 변수를 만들어 볼것임.(해당 지역 건물의 가격을 100으로 기준잡고 등락을 숫자로 보여주는 것)\n",
        "##출처 : https://data.seoul.go.kr/dataList/801/S/2/datasetView.do \n",
        "\n",
        "Price_idx = {'종로구':100.2,'중구':96.9,'용산구':101.4,'성동구':99.0,'광진구':100.0,'동대문구':97.7,\n",
        "      '중랑구':98.8,'성북구':96.5,'강북구':98.8,'도봉구':96.0,'노원구':93.8,'은평구':98.3,\n",
        "      '서대문구':97.4,'마포구':98.8,'양천구':99.1,'강서구':98.6,'구로구':99.0,'금천구':98.5,\n",
        "      '영등포구':98.1,'동작구':100.2,'관악구':98.7,'서초구':103.1,'강남구':101.2,'송파구':98.8,'강동구':99.0}\n",
        "df.loc[:, '매매가격지수'] = df['지역구'].apply(lambda x : Price_idx[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPxjvosXd938"
      },
      "source": [
        "#################################################################################\n",
        "# TODO: One hot encoding의 컬럼수 조정                                          #\n",
        "#                                                                               #\n",
        "# 1. training set과 test set의 범주형 변수의 종류가 달라질 수 있으므로 이를 train  \n",
        "#  set의 컬럼으로 통일 (index.isin() 활용)                                         \n",
        "#################################################################################\n",
        "\n",
        "#해당 test set에 대한 encoding 부터 진행 >> feature importance 분석으로 인해 encoding 방식을 바꾸어서 진행함.\n",
        "CATEGORICAL = ['용도지역', '건축물주용도', '도로조건', '지역구'] ##training set에 있던 범주형 변수들\n",
        "\n",
        "def usage_check(val):\n",
        "  if val.find('주거') >= 0 or val.find('상업') >= 0:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "\n",
        "for i in CATEGORICAL:\n",
        "  if i in df.columns:\n",
        "    if i == '용도지역': #용도지역 encoding\n",
        "      df.loc[:, '용도지역'] = df['용도지역'].apply(usage_check)\n",
        "\n",
        "    elif i == '건축물주용도': #건축물주용도 encoding\n",
        "      #feature engineering에서 median을 통해 구한 encoding rule\n",
        "      const_usage_dict = {'교육연구': 0, '기타': 1, '제2종근린생활': 2, '판매': 3, '업무': 4, '제1종근린생활': 5, '숙박': 6}\n",
        "\n",
        "      df.loc[:, '건축물주용도'] = df['건축물주용도'].apply(lambda x : const_usage_dict[x])\n",
        "\n",
        "    elif i == '도로조건': #도로조건 encoding\n",
        "      road_con = {'25m미만' : 0, '12m미만' : 1, '8m미만' : 2, '25m이상' : 3}\n",
        "      df.loc[:, '도로조건'] = df['도로조건'].apply(lambda x : (road_con[x]))\n",
        "\n",
        "    else: #지역구 encoding\n",
        "\n",
        "      #feature engineering에서 mean을 통한 군집화를 통해 정한 encoding rule\n",
        "      loc_number = {'강남구' : 3, '강동구' : 2, '강북구' : 0, '강서구' : 1, '관악구' : 0, '광진구' : 2, '구로구' : 0, '금천구' : 0, '노원구' : 1,\n",
        "              '도봉구' : 0, '동대문구' : 0, '동작구' : 1, '마포구' : 2, '서대문구' : 2, '서초구' : 3, '성동구' : 2, '성북구' : 0, '송파구' : 3,\n",
        "              '양천구' : 1, '영등포구' : 1, '용산구' : 3, '은평구' : 1, '종로구' : 3, '중구' : 3, '중랑구' : 0}\n",
        "\n",
        "      df.loc[:, '지역구'] = df['지역구'].apply(lambda x : (loc_number[x]))\n",
        "\n",
        "##encoding이 모두 끝나면 필요없는 열들을 모두 제외해서 training set과 맞추기\n",
        "\n",
        "need_col = ['전용/연면적(㎡)', '층', '건물년식', '평당가격', '거래금액(만원)_adj', '용도지역', '건축물주용도', '도로조건', '지역구']\n",
        "\n",
        "for i in df.columns:\n",
        "  if i not in need_col:\n",
        "    df.drop(i, axis = 1, inplace = True)\n",
        "\n",
        "#training set과 column 순서 맞추기    \n",
        "df = df[X_train.columns.to_list()]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNRWkomkgrjm"
      },
      "source": [
        "#################################################################################\n",
        "# TODO: Normalize : training set을 기준으로 진행                                #\n",
        "#                                                                               #\n",
        "# 1. training set의 cache를 활용하여 test set normalize    \n",
        "# ---- z_normalize_val(____, cache)                           \n",
        "#################################################################################\n",
        "X_test = df.copy()\n",
        "X_test_norm = X_test.copy()\n",
        "X_test_norm.loc[:, ['전용/연면적(㎡)','층','건물년식']] = z_normalize_val(X_test, ['전용/연면적(㎡)','층','건물년식'], cache)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YktmxNQAgwI5"
      },
      "source": [
        "# Print your test 거래금액 Mean Absolute Error: this should be below 11,000\n",
        "\n",
        "print('Validation MSE(㎡당 가격): ', np.mean(np.square(best_rf.predict(X_test_norm) - y_price)))\n",
        "print('Validation MAE(㎡당 가격):', np.mean(np.abs(best_rf.predict(X_test_norm) - y_price)))\n",
        "\n",
        "_price = X_test.loc[:, '전용/연면적(㎡)'] * best_rf.predict(X_test_norm)\n",
        "\n",
        "print('Validation MSE(거래 금액): ', np.mean(np.square(_price - y_real)))\n",
        "print('Validation MAE(거래 금액): ', np.mean(np.abs(_price - y_real)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Adaboost implementation added for test set\n",
        "\n",
        "# Print your test 거래금액 Mean Absolute Error: this should be below 11,000\n",
        "\n",
        "print('Validation MSE(㎡당 가격): ', np.mean(np.square(best_ab.predict(X_test_norm) - y_price)))\n",
        "print('Validation MAE(㎡당 가격):', np.mean(np.abs(best_ab.predict(X_test_norm) - y_price)))\n",
        "\n",
        "_price = X_test.loc[:, '전용/연면적(㎡)'] * best_ab.predict(X_test_norm)\n",
        "\n",
        "print('Validation MSE(거래 금액): ', np.mean(np.square(_price - y_real)))\n",
        "print('Validation MAE(거래 금액): ', np.mean(np.abs(_price - y_real)))"
      ],
      "metadata": {
        "id": "wgbd-BjFxXri"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}